{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "need to upload data.zip with data and sparse_vector folder"
      ],
      "metadata": {
        "id": "lrWR59uIKroT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip data.zip\n",
        "import sys\n",
        "sys.path.append('/content')\n"
      ],
      "metadata": {
        "id": "niiVOqOPKnTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrPyWNySKYlx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy\n",
        "from tqdm import trange\n",
        "from tqdm.notebook import tqdm\n",
        "import sys\n",
        "import os\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "from joblib import Parallel, delayed, dump, load\n",
        "from matplotlib import pyplot as plt\n",
        "from sparse_vector.sparse_vector import SparseVector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gw88PNPgKYlx"
      },
      "outputs": [],
      "source": [
        "chroms = [f'chr{i}' for i in list(range(1, 23)) + ['X', 'Y','M']]\n",
        "all_features = [i[:-4] for i in os.listdir('data/hg19_features/sparse/') if i.endswith('.pkl')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkvSECG_KYly"
      },
      "outputs": [],
      "source": [
        "groups = ['DNase-seq', 'Histone', 'RNA polymerase', 'TFs and others']\n",
        "feature_names = [i for i in all_features if (i.split('_')[0] in groups)]\n",
        "\n",
        "def chrom_reader(chrom):\n",
        "    files = sorted([i for i in os.listdir(f'data/hg19_dna/') if f\"{chrom}_\" in i])\n",
        "    return ''.join([load(f\"data/hg19_dna/{file}\") for file in files])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "6a7a761dcc1543228ca2b063f32c69dc",
            "decd5d5b0b764eacbafabdcf765bd9e9"
          ]
        },
        "id": "SQDgZssSKYly",
        "outputId": "8f9d7404-6888-4235-d92a-e82532a45947"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a7a761dcc1543228ca2b063f32c69dc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=25), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "decd5d5b0b764eacbafabdcf765bd9e9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=1054), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "CPU times: user 12.6 s, sys: 5.35 s, total: 17.9 s\n",
            "Wall time: 17.9 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# load all the data\n",
        "DNA = {chrom:chrom_reader(chrom) for chrom in tqdm(chroms)}\n",
        "ZDNA = load('data/hg19_zdna/sparse/ZDNA.pkl')\n",
        "ZHUNT = load('data/hg19_zdna/sparse/ZHUNT.pkl')\n",
        "\n",
        "DNA_features = {feture: load(f'data/hg19_features/sparse/{feture}.pkl')\n",
        "                for feture in tqdm(feature_names)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF1DI75mKYly"
      },
      "source": [
        "# All DL code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54f4irMkKYly"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils import data\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0bPx9rJKYlz"
      },
      "outputs": [],
      "source": [
        "class Dataset(data.Dataset):\n",
        "    def __init__(self, chroms, features,\n",
        "                 dna_source, features_source,\n",
        "                 labels_source, intervals):\n",
        "        self.chroms = chroms\n",
        "        self.features = features\n",
        "        self.dna_source = dna_source\n",
        "        self.features_source = features_source\n",
        "        self.labels_source = labels_source\n",
        "        self.intervals = intervals\n",
        "        self.le = LabelBinarizer().fit(np.array([[\"A\"], [\"C\"], [\"T\"], [\"G\"]]))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.intervals)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        interval = self.intervals[index]\n",
        "        chrom = interval[0]\n",
        "        begin = int(interval[1])\n",
        "        end = int(interval[2])\n",
        "        dna_OHE = self.le.transform(list(self.dna_source[chrom][begin:end].upper()))\n",
        "\n",
        "        feature_matr = []\n",
        "        for feature in self.features:\n",
        "            source = self.features_source[feature]\n",
        "            feature_matr.append(source[chrom][begin:end])\n",
        "        if len(feature_matr) > 0:\n",
        "            X = np.hstack((dna_OHE, np.array(feature_matr).T/1000)).astype(np.float32)\n",
        "        else:\n",
        "            X = dna_OHE.astype(np.float32)\n",
        "        y = self.labels_source[interval[0]][interval[1]: interval[2]]\n",
        "\n",
        "        return (X, y)\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrY_Vk3MKYlz",
        "outputId": "de16ac94-fcc5-4c32-f872-3d05a6f4032d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 49850/49850 [00:01<00:00, 34378.21it/s]\n",
            "100%|██████████| 48639/48639 [00:01<00:00, 33132.59it/s]\n",
            "100%|██████████| 39604/39604 [00:01<00:00, 35528.40it/s]\n",
            "100%|██████████| 38230/38230 [00:01<00:00, 32598.79it/s]\n",
            "100%|██████████| 36183/36183 [00:01<00:00, 35343.51it/s]\n",
            "100%|██████████| 34223/34223 [00:01<00:00, 32222.80it/s]\n",
            "100%|██████████| 31827/31827 [00:00<00:00, 34798.99it/s]\n",
            "100%|██████████| 29272/29272 [00:00<00:00, 35216.21it/s]\n",
            "100%|██████████| 28242/28242 [00:00<00:00, 35509.09it/s]\n",
            "100%|██████████| 27106/27106 [00:00<00:00, 30589.87it/s]\n",
            "100%|██████████| 27001/27001 [00:00<00:00, 35329.94it/s]\n",
            "100%|██████████| 26770/26770 [00:00<00:00, 35564.51it/s]\n",
            "100%|██████████| 23033/23033 [00:00<00:00, 35120.28it/s]\n",
            "100%|██████████| 21469/21469 [00:00<00:00, 35350.21it/s]\n",
            "100%|██████████| 20506/20506 [00:00<00:00, 35283.34it/s]\n",
            "100%|██████████| 18070/18070 [00:00<00:00, 29094.21it/s]\n",
            "100%|██████████| 16239/16239 [00:00<00:00, 35088.34it/s]\n",
            "100%|██████████| 15615/15615 [00:00<00:00, 35134.32it/s]\n",
            "100%|██████████| 11825/11825 [00:00<00:00, 35522.65it/s]\n",
            "100%|██████████| 12605/12605 [00:00<00:00, 33810.63it/s]\n",
            "100%|██████████| 9625/9625 [00:00<00:00, 35514.21it/s]\n",
            "100%|██████████| 10260/10260 [00:00<00:00, 35449.20it/s]\n",
            "100%|██████████| 31054/31054 [00:00<00:00, 35272.37it/s]\n",
            "100%|██████████| 11874/11874 [00:00<00:00, 35469.71it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 7762.44it/s]\n"
          ]
        }
      ],
      "source": [
        "width = 5000\n",
        "\n",
        "np.random.seed(10)\n",
        "\n",
        "ints_in = []\n",
        "ints_out = []\n",
        "\n",
        "for chrm in chroms:\n",
        "    for st in trange(0, ZDNA[chrm].shape - width, width):\n",
        "        interval = [st, min(st + width, ZDNA[chrm].shape)]\n",
        "        if ZDNA[chrm][interval[0]: interval[1]].any():\n",
        "            ints_in.append([chrm, interval[0], interval[1]])\n",
        "        else:\n",
        "            ints_out.append([chrm, interval[0], interval[1]])\n",
        "\n",
        "ints_in = np.array(ints_in)\n",
        "ints_out = np.array(ints_out)[np.random.choice(range(len(ints_out)), size=len(ints_in) * 3, replace=False)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ppdGBh77KYlz"
      },
      "outputs": [],
      "source": [
        "equalized = np.vstack((ints_in, ints_out))\n",
        "equalized = [[inter[0], int(inter[1]), int(inter[2])] for inter in equalized]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z400hKYMKYlz",
        "outputId": "2f4067b2-ab59-4977-b58c-5903952a2a6c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n"
          ]
        }
      ],
      "source": [
        "train_inds, test_inds = next(StratifiedKFold().split(equalized, [f\"{int(i < 400)}_{elem[0]}\"\n",
        "                                                                 for i, elem\n",
        "                                                                 in enumerate(equalized)]))\n",
        "\n",
        "train_intervals, test_intervals = [equalized[i] for i in train_inds], [equalized[i] for i in test_inds]\n",
        "\n",
        "train_dataset = Dataset(chroms, feature_names,\n",
        "                       DNA, DNA_features,\n",
        "                       ZDNA, train_intervals)\n",
        "\n",
        "test_dataset = Dataset(chroms, feature_names,\n",
        "                       DNA, DNA_features,\n",
        "                       ZDNA, test_intervals)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Liwb_XGwKYlz"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import roc_auc_score, f1_score\n",
        "from IPython.display import clear_output\n",
        "\n",
        "class DeepZ(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.rnn = nn.LSTM(1058, 500, 2, bidirectional=True)\n",
        "        self.seq = nn.Sequential(\n",
        "                    nn.Dropout(0.5),\n",
        "                    nn.Linear(2 * 500, 500),\n",
        "                    nn.Sigmoid(),\n",
        "                    nn.Dropout(0.5),\n",
        "                    nn.Linear(500, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, (h_n, c_n) = self.rnn(x)\n",
        "        x = self.seq(x)\n",
        "        return F.log_softmax(x, dim=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMlOgvIRKYlz"
      },
      "outputs": [],
      "source": [
        "params = {'batch_size':20,\n",
        "          'num_workers':20,\n",
        "          'shuffle':True}\n",
        "\n",
        "loader_train = data.DataLoader(train_dataset, **params)\n",
        "loader_test = data.DataLoader(test_dataset, **params)\n",
        "\n",
        "def loss_func(output, y_batch):\n",
        "    return torch.nn.NLLLoss()(torch.transpose(output, 2, 1), y_batch)\n",
        "\n",
        "\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train_epoch(model, optimizer):\n",
        "    loss_log, acc_log, roc_auc_log, f1_log = [], [], [], []\n",
        "    model.train()\n",
        "\n",
        "    for X_batch, y_batch in tqdm(loader_train, desc=\"Training\", leave=False):\n",
        "        X_batch, y_batch = X_batch.cuda(), y_batch.cuda().long()\n",
        "        optimizer.zero_grad()\n",
        "        output = model(X_batch)\n",
        "\n",
        "        pred = torch.argmax(output, dim=2)\n",
        "        y_true = y_batch.cpu().numpy().flatten()\n",
        "        y_pred = nn.Softmax(dim=1)(output)[:, :, 1].detach().cpu().numpy().flatten()\n",
        "        y_pred_labels = pred.cpu().numpy().flatten()\n",
        "\n",
        "        roc_auc = 0\n",
        "        if np.std(y_true) != 0:\n",
        "            roc_auc = roc_auc_score(y_true, y_pred)\n",
        "        f1 = f1_score(y_true, y_pred_labels)\n",
        "        acc = torch.mean((pred == y_batch).float()).cpu().item()\n",
        "        loss = loss_func(output, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_log.append(loss.item())\n",
        "        acc_log.append(acc)\n",
        "        roc_auc_log.append(roc_auc)\n",
        "        f1_log.append(f1)\n",
        "\n",
        "    return loss_log, acc_log, roc_auc_log, f1_log\n",
        "\n",
        "def test(model):\n",
        "    loss_log, acc_log, roc_auc_log, f1_log = [], [], [], []\n",
        "    model.eval()\n",
        "    means = []\n",
        "\n",
        "    for X_batch, y_batch in tqdm(loader_test, desc=\"Testing\", leave=False):\n",
        "        X_batch, y_batch = X_batch.cuda(), y_batch.cuda().long()\n",
        "        output = model(X_batch)\n",
        "\n",
        "        means.append(y_batch.sum().cpu() / y_batch.shape[0])\n",
        "\n",
        "        pred = torch.argmax(output, dim=2)\n",
        "        y_true = y_batch.cpu().numpy().flatten()\n",
        "        y_pred = nn.Softmax(dim=1)(output)[:, :, 1].detach().cpu().numpy().flatten()\n",
        "        y_pred_labels = pred.cpu().numpy().flatten()\n",
        "\n",
        "        roc_auc = 0\n",
        "        if np.std(y_true) != 0:\n",
        "            roc_auc = roc_auc_score(y_true, y_pred)\n",
        "        f1 = f1_score(y_true, y_pred_labels)\n",
        "        acc = torch.mean((pred == y_batch).float()).cpu().item()\n",
        "        loss = loss_func(output, y_batch)\n",
        "\n",
        "        loss_log.append(loss.item())\n",
        "        acc_log.append(acc)\n",
        "        roc_auc_log.append(roc_auc)\n",
        "        f1_log.append(f1)\n",
        "\n",
        "    return loss_log, acc_log, roc_auc_log, f1_log\n",
        "\n",
        "def plot_history(train_history, valid_history, title, BatchSize, epoch_to_show=20):\n",
        "    plt.figure(figsize=(epoch_to_show, 4))\n",
        "    plt.title(title)\n",
        "\n",
        "    epoch_num = len(valid_history)\n",
        "    train_history = np.array([None] * (BatchSize * epoch_to_show) + train_history)\n",
        "    valid_history = np.array([None] * epoch_to_show + valid_history)\n",
        "\n",
        "    plt.plot(np.linspace(epoch_num-epoch_to_show+1, epoch_num+1, (epoch_to_show+1)*BatchSize),\n",
        "             train_history[-(epoch_to_show+1)*BatchSize:], c='red', label='train')\n",
        "    plt.plot(np.linspace(epoch_num-epoch_to_show+1, epoch_num+1, epoch_to_show+1),\n",
        "                valid_history[-epoch_to_show-1:], c='green', label='test')\n",
        "\n",
        "    plt.ylim((0, 1))\n",
        "    plt.yticks(np.linspace(0, 1, 11))\n",
        "    plt.xticks(np.arange(epoch_num-epoch_to_show+1, epoch_num+2),\n",
        "              np.arange(epoch_num-epoch_to_show, epoch_num+1).astype(int))\n",
        "    plt.xlabel('train steps')\n",
        "    plt.legend(loc='best')\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "def train(model, opt, n_epochs):\n",
        "    train_log, train_acc_log, train_auc_log, train_f1_log = [], [], [], []\n",
        "    val_log,   val_acc_log,   val_auc_log, val_f1_log   = [], [], [], []\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        print(\"Epoch {} of {}\".format(epoch + 1, n_epochs))\n",
        "        train_loss, train_acc, train_auc, train_f1 = train_epoch(model, opt)\n",
        "        val_loss, val_acc, val_auc, val_f1 = test(model)\n",
        "\n",
        "        BatchSize = len(train_loss)\n",
        "\n",
        "        train_log.extend(train_loss)\n",
        "        train_acc_log.extend(train_acc)\n",
        "        train_auc_log.extend(train_auc)\n",
        "        train_f1_log.extend(train_f1)\n",
        "\n",
        "        val_log.append(np.mean(val_loss))\n",
        "        val_acc_log.append(np.mean(val_acc))\n",
        "        val_auc_log.append(np.mean(val_auc))\n",
        "        val_f1_log.append(np.mean(val_f1))\n",
        "#         raise BaseException\n",
        "\n",
        "        if (epoch % 1) == 0:\n",
        "            clear_output()\n",
        "            plot_history(train_log,     val_log,     'Loss',     BatchSize)\n",
        "            plot_history(train_acc_log, val_acc_log, 'Accuracy', BatchSize)\n",
        "            plot_history(train_auc_log, val_auc_log, 'Auc',      BatchSize)\n",
        "            plot_history(train_f1_log, val_f1_log,   'F1',       BatchSize)\n",
        "            print(\"Epoch {} AUC = {:.2%}\".format(epoch+1, 1 - val_auc_log[-1]))\n",
        "            print(\"Epoch {} accuracy = {:.2%}\".format(epoch+1, 1 - val_acc_log[-1]))\n",
        "\n",
        "\n",
        "    print(\"Final AUC: {:.2}\".format(1 - val_auc_log[-1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leHAJpX9KYlz"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNb6jGTnKYl0"
      },
      "outputs": [],
      "source": [
        "def count_parameters(model):\n",
        "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "    return sum([np.prod(p.size()) for p in model_parameters])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bY5AiVKtKYl0",
        "outputId": "3ad0f59b-d361-4a3e-e219-c9b4cbfe87db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of trainable parameters: 12749502\n"
          ]
        }
      ],
      "source": [
        "model = DeepZ()\n",
        "model = model.cuda()\n",
        "print(\"Total number of trainable parameters:\", count_parameters(model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "akHoc76QKYl0"
      },
      "outputs": [],
      "source": [
        "opt = torch.optim.RMSprop(model.parameters(), lr=10**-4, weight_decay=10**-4)\n",
        "train(model, opt, 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2UhB2QzzKYl0"
      },
      "outputs": [],
      "source": [
        "# prompt: save trained model with timestamp\n",
        "\n",
        "import datetime\n",
        "\n",
        "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "model_filename = f\"deepz_model_0.5_{timestamp}.pth\"\n",
        "torch.save(model.state_dict(), model_filename)\n",
        "print(f\"Model saved as {model_filename}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}